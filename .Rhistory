import numpy as np
import trustscore # you need to have trustscore.py in the same folder as this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras
import pandas as pd
# heads up! there might be some scary errors about "dlerror: cudart64_110.dll not found". It's just a warning and you can ignore it.
# Import penguins from R into python
penguins_data = r.penguins_data
penguins_target = r.penguins_target
# encode each penguin species to be a number.
# purpose: make it easier for the model to assign a species and a trust score to the species prediction.
dictionary = {}
current_index = 0
def encode(value):
if value in dictionary:
return dictionary[value]
else:
global current_index
new_index = current_index
dictionary[value] = new_index
current_index = current_index + 1
return new_index
X_penguins = penguins_data
# SARAH SOLVE: UNNEST ALL OF THESE
# is it the .ravel() or the map or the list?
y_penguins = list(map(encode, penguins_target.values.ravel()))
# need to unravel it after?
print(dictionary) # dictionary with each penguin sepecies connected to its assigned number
# prep the model
from sklearn.linear_model import LogisticRegression
# Train logistic regression on digits.
model = LogisticRegression()
# implement the model
model.fit(X_penguins, y_penguins)
# Create outputs on testing set.
y_pred = model.predict(X_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore()
X_penguins = X_penguins.to_numpy()
# y_penguins = y_penguins.to_numpy()
trust_model.fit(X_penguins, y_penguins)
# Efunction needs:
#     def fit(self, X: np.array, y: np.array):
#         """Initialize trust score precomputations with training data.
#
#     WARNING: assumes that the labels are 0-indexed (i.e.
#     0, 1,..., n_labels-1).
#
#     Args:
#     X: an array of sample points.
#     y: corresponding labels.
#     """
# so...
# newest error: ValueError: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.
# so this array us a problem with the samples. the 4 in the shape is the number of columns.
# where did the samples go?
# np.shape(y_penguins)
# (333,)
# --> PROBLEM PROBLEM PROBLEM!
# needs to be 333,1
# also, y_penguins: AttributeError: 'list' object has no attribute 'to_numpy' ... b/c already an array. this probably could be its own code chunk or even at the begining when importing the data.
type(y_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore()
X_penguins = X_penguins.to_numpy()
y_penguins2 = y_penguins.to_numpy()
trust_model.fit(X_penguins, y_penguins2)
# Efunction needs:
#     def fit(self, X: np.array, y: np.array):
#         """Initialize trust score precomputations with training data.
#
#     WARNING: assumes that the labels are 0-indexed (i.e.
#     0, 1,..., n_labels-1).
#
#     Args:
#     X: an array of sample points.
#     y: corresponding labels.
#     """
# so...
# newest error: ValueError: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.
# so this array us a problem with the samples. the 4 in the shape is the number of columns.
# where did the samples go?
# np.shape(y_penguins)
# (333,)
# --> PROBLEM PROBLEM PROBLEM!
# needs to be 333,1
# also, y_penguins: AttributeError: 'list' object has no attribute 'to_numpy' ... b/c already an array. this probably could be its own code chunk or even at the begining when importing the data.
trust_model.fit(X_penguins, y_penguins2)
y_penguins2 = y_penguins.to_numpy()
y_penguins2 = np.array(y_penguins)
trust_model.fit(X_penguins, y_penguins2)
# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)
print(trust_score) # prints the trust scores for each point in the inputted dataset
# type(trust_score) # this trust_score data frame has a class of <class 'numpy.ndarray'>
type(y_pred)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(eval = FALSE)
library(reticulate) # provides a comprehensive set of tools for interoperability between Python and R.
# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::py_install("pandas")
# setting up the Python environment and bringing in the required Python packages is important.
# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.
# common trouble shooting:
# if you're missing a package then try adding its name in an additonal line of py_install
# if py_install isn't working then try adding the pip = TRUE argument to try installing
# the library through pip rather than anaconda
reticulate::repl_python()
library(palmerpenguins)
library(dplyr)
# data
penguins_df <- penguins %>%
dplyr::filter(complete.cases(.)) # remove all lines with NaN so the model can be fit on the data (later)
penguins_data <- penguins_df %>%
dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)
# target: species
penguins_target <- penguins_df %>%
dplyr::select(species)
# make each species into a categorical variable number
reticulate::repl_python()
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(eval = FALSE)
# Load the R libraries
library(palmerpenguins) # bring in data about penguin species
library(dplyr) # tools for data wrangling in R
library(reticulate) # provides a comprehensive set of tools for interoperability between Python and R.
# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::py_install("pandas")
# setting up the Python environment and bringing in the required Python packages is important.
# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.
# common trouble shooting:
# if you're missing a package then try adding its name in an additional line of py_install
# if py_install isn't working then try adding the pip = TRUE argument to try installing
# the library through pip rather than anaconda
reticulate::repl_python()
# data wrangling
# remove all lines with NaN and N/A so the model can be fit on the data
penguins_df <- penguins %>%
dplyr::filter(complete.cases(.))
# choose the data columns to use in the model
penguins_data <- penguins_df %>%
dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)
# prediction target: species
penguins_target <- penguins_df %>%
dplyr::select(species)
reticulate::repl_python()
