import numpy as np
import trustscore # you need to have trustscore.py in the same folder as this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras
# heads up! there might be some scary errors about "dlerror: cudart64_110.dll not found". It's just a warning and you can ignore it.
pip install tensorflow==1.2.0 --ignore-installed
# Import penguins from R into python
penguins_data = r.penguins_data
penguins_target = r.penguins_target
X_penguins = penguins_data
y_penguins = penguins_target
from sklearn.linear_model import LogisticRegression
# Train logistic regression on digits.
model = LogisticRegression()
model.fit(X_penguins, y_penguins)
# Get outputs on testing set.
y_pred = model.predict(X_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore()
trust_model.fit(X_penguins, y_penguins)
# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)
print(trust_score) # prints the trust scores for each point in the inputted dataset
# type(trust_score) # this trust_score data frame has a class of <class 'numpy.ndarray'>
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_penguins, y_penguins)
model.fit(X_penguins)
class(X_penguins)
type(X_penguins)
type(Y_penguins)
print(X_penguins)
print(y_penguins)
import numpy as np
import trustscore # you need to have trustscore.py in the same folder as this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras
# heads up! there might be some scary errors about "dlerror: cudart64_110.dll not found". It's just a warning and you can ignore it.
# Import penguins from R into python
penguins_data = r.penguins_data
penguins_target = r.penguins_target
X_penguins = penguins_data
y_penguins = penguins_target
# Import penguins from R into python
penguins_data = r.penguins_data
penguins_target = r.penguins_target
X_penguins = penguins_data
y_penguins = penguins_target
from sklearn.linear_model import LogisticRegression
# Train logistic regression on digits.
model = LogisticRegression()
model.fit(X_penguins, y_penguins)
# Get outputs on testing set.
y_pred = model.predict(X_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore()
trust_model.fit(X_penguins, y_penguins)
# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)
print(trust_score) # prints the trust scores for each point in the inputted dataset
# type(trust_score) # this trust_score data frame has a class of <class 'numpy.ndarray'>
class(X_penguins)
type(X_penguins)
from sklearn.linear_model import LogisticRegression
# Train logistic regression on digits.
model = LogisticRegression()
X_penguins=X_penguins.values()
model.fit(X_penguins, y_penguins)
# Get outputs on testing set.
y_pred = model.predict(X_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore()
trust_model.fit(X_penguins, y_penguins)
# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)
print(trust_score) # prints the trust scores for each point in the inputted dataset
# type(trust_score) # this trust_score data frame has a class of <class 'numpy.ndarray'>
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(eval = FALSE)
library(reticulate) # provides a comprehensive set of tools for interoperability between Python and R.
# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
# setting up the Python environment and bringing in the required Python packages is important.
# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.
# common trouble shooting:
# if you're missing a package then try adding its name in an additonal line of py_install
# if py_install isn't working then try adding the pip = TRUE argument to try installing
# the library through pip rather than anaconda
reticulate::repl_python()
library(palmerpenguins)
library(dplyr)
# data
penguins_df <- penguins
# target: species
# data: bill_length_mm, bil_depth_mm, flipper_length_mm, body_mass_g
penguins_data <- penguins_df %>%
# dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)
dplyr::select(bill_length_mm)
penguins_target <- penguins_df %>%
dplyr::select(species)
reticulate::repl_python()
# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::repl_python()
# setting up the Python environment and bringing in the required Python packages is important.
quit
# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.
# common trouble shooting:
# if you're missing a package then try adding its name in an additonal line of py_install
# if py_install isn't working then try adding the pip = TRUE argument to try installing
# the library through pip rather than anaconda
reticulate::repl_python()
