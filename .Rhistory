import numpy as np
import trustscore # you need to have trustscore.py in the same folder as this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras
import pandas as pd
# heads up! there might be some scary errors about "dlerror: cudart64_110.dll not found". It's just a warning and you can ignore it.
# Import penguins from R into python
penguins_data = r.penguins_data
penguins_target = r.penguins_target
X_penguins = penguins_data
y_penguins = penguins_target
# convert the imported datasets from python dictionaries to python floats
# my_dict = penguins_target
# df = pd.DataFrame(list(my_dict.items()),columns = ['species'])
# prep the model
from sklearn.linear_model import LogisticRegression
# Train logistic regression on digits.
model = LogisticRegression()
# implement the model
model.fit(X_penguins, y_penguins.values.ravel())
# note: I added the ravel part to make y a 1d array and solve the below error:
#" /Users/sgill/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel()."
# Get outputs on testing set.
y_pred = model.predict(X_penguins)
# Initialize trust score.
trust_model = trustscore.TrustScore() # SARAH ERROR: TypeError: 'Series' object cannot be interpreted as an integer
trust_model.fit(X_penguins, y_penguins.values.ravel())
# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)
print(trust_score) # prints the trust scores for each point in the inputted dataset
# type(trust_score) # this trust_score data frame has a class of <class 'numpy.ndarray'>
trust_model.fit(X_penguins, y_penguins)
model.fit(X_penguins, y_penguins.values.ravel())
y_pred = model.predict(X_penguins)
trust_model = trustscore.TrustScore()
trust_model.fit(X_penguins, y_penguins.values.ravel())
trust_model.fit(X_penguins, y_penguins)
trust_model.fit(X_penguins, str(y_penguins))
trust_score = trust_model.get_score(X_penguins, y_pred)
trust_model.fit(X_penguins, y_penguins)
trust_model.fit(X_penguins, y_penguins.values.ravel())
trust_score = trust_model.get_score(X_penguins, y_pred)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(eval = FALSE)
library(reticulate) # provides a comprehensive set of tools for interoperability between Python and R.
# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::py_install("pandas")
# setting up the Python environment and bringing in the required Python packages is important.
# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.
# common trouble shooting:
# if you're missing a package then try adding its name in an additonal line of py_install
# if py_install isn't working then try adding the pip = TRUE argument to try installing
# the library through pip rather than anaconda
reticulate::repl_python()
library(palmerpenguins)
library(dplyr)
# data
penguins_df <- penguins %>%
dplyr::filter(complete.cases(.)) # remove all lines with NaN so the model can be fit on the data (later)
penguins_data <- penguins_df %>%
# dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)
dplyr::select(bill_length_mm)
# target: species
penguins_target <- penguins_df %>%
dplyr::select(species)
reticulate::repl_python()
